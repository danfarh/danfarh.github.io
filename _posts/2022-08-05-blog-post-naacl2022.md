---
title: 'GlobEnc: Quantifying Global Token Attribution by Incorporating the Whole Encoder Layer in Transformers'
date: 2022-08-05
permalink: /posts/GlobEnc/
tags:
  - Natural Language Processing
  - Attention
  - Transformers
---
<img style="margin: 9px; border-radius: 2%;" align="right" src="/files/publications/2022_naacl_globenc/globenc.png" width="270" >
<!-- This is a post for the NAACL 2022 paper [GlobEnc: Quantifying Global Token Attribution by Incorporating the Whole Encoder Layer in Transformers](https://aclanthology.org/2022.naacl-main.19/) -->
<!-- <br> -->
<span class="authors">
(Ali Modarressi\*, Mohsen Fayyaz\*, Yadollah Yaghoobzadeh, Mohammad Taher Pilehvar)
</span>
<!-- > There has been a growing interest in interpreting the underlying dynamics of Transformers. While self-attention patterns were initially deemed as the primary choice, recent studies have shown that integrating other components can yield more accurate explanations. This paper introduces a novel token attribution analysis method that incorporates all the components in the encoder block and aggregates this throughout layers. We quantitatively and qualitatively demonstrate that our method can yield faithful and meaningful global token attributions. Our extensive experiments reveal that incorporating almost every encoder component results in increasingly more accurate analysis in both local (single layer) and global (the whole model) settings. Our global attribution analysis surpasses previous methods by achieving significantly higher results in various datasets.\\ -->
> NAACL 2022
> - We expand the scope of analysis from attention block in Transformers to the whole encoder.
> - Our method significantly improves over existing techniques for quantifying global token attributions.
> - We qualitatively demonstrate that the attributions obtained by our method are plausibly interpretable. \\
<br>
<a class="blue-button read-paper-button" href="https://aclanthology.org/2022.naacl-main.19/">read paper</a>
